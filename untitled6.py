# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WJeAIMkg9VPnfk6khk5Xh_cIAEeEAvkY
"""

from google.colab import drive

drive.mount('/content/drive')

import os
import numpy as np
import pandas as pd
from mpl_toolkits.axes_grid1 import ImageGrid
import matplotlib.pyplot as plt
from keras.utils.vis_utils import plot_model
from tensorflow.keras.preprocessing import image
import tensorflow as tf
from tensorflow.keras import applications
from PIL import Image
from tensorflow.keras.preprocessing.image import  ImageDataGenerator
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py
    
from helper_functions import plot_loss_curves

SAMPLE_PER_CATEGORY = 200
SEED = 42
WIDTH = 128
HEIGHT = 128
DEPTH = 3
INPUT_SHAPE = (WIDTH, HEIGHT, DEPTH)

data_dir = '../input/augmented-alzheimer-mri-dataset-v2/data'
train_dir = os.path.join(data_dir, 'train')
test_dir = os.path.join(data_dir, 'val')

CATEGORIES = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']
NUM_CATEGORIES = len(CATEGORIES)
NUM_CATEGORIES

#train path
train_p = "/content/drive/MyDrive/Alzheimer_s Dataset/train"
#test path
test_p = "/content/drive/MyDrive/Alzheimer_s Dataset/test"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_batches = train_datagen.flow_from_directory(directory=train_p, 
                                                  classes=['NonDemented', 'VeryMildDemented', 
                                                           'MildDemented', 'ModerateDemented'], 
                                                  target_size=(224, 224),
                                                  subset='training', 
                                                  batch_size=10)

validation_batches = train_datagen.flow_from_directory(directory=train_p, 
                                                       classes=['NonDemented', 'VeryMildDemented', 
                                                                'MildDemented', 'ModerateDemented'], 
                                                       target_size=(224, 224),
                                                       subset='validation',
                                                       batch_size=10)

test_datagen = ImageDataGenerator(rescale=1./255)

test_batches = test_datagen.flow_from_directory(directory=test_p, 
                                                classes=['NonDemented', 'VeryMildDemented', 
                                                         'MildDemented', 'ModerateDemented'], 
                                                target_size=(224, 224),
                                                batch_size=10, 
                                                shuffle=False)

def read_img(filepath, size):
    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)
    img = image.img_to_array(img)
    return img

import keras
import keras.utils
from keras import utils as np_utils

import os
import pandas as pd
import numpy as np
from matplotlib import image
import seaborn as sns
import matplotlib.pyplot as plt
from skimage.transform import resize
from skimage.io import imread
from skimage.color import rgb2gray
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import pandas as pd 
import numpy as np 
import cv2
import matplotlib.pyplot as plt
import warnings
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.preprocessing import image, image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow import keras
import tensorflow 
import tensorflow as tf

pathtest = '/content/drive/MyDrive/Alzheimer_s Dataset-2/test'
pathtrain = '/content/drive/MyDrive/Alzheimer_s Dataset-2/train'

class1 = '/content/drive/MyDrive/Alzheimer_s Dataset-2/train/VeryMildDemented' 
class2 = '/content/drive/MyDrive/Alzheimer_s Dataset-2/train/MildDemented'
class3 = '/content/drive/MyDrive/Alzheimer_s Dataset-2/train/ModerateDemented'
class0 = '/content/drive/MyDrive/Alzheimer_s Dataset-2/train/NonDemented'

def create_model():
   
    resnet_model = tf.keras.applications.resnet_v2.ResNet152V2(
        weights='imagenet',
        include_top = False,
        input_shape = (224, 224, 3)
    )
    
    for layers in resnet_model.layers[:100]:
        layers.trainable = False
    for layers in resnet_model.layers[100:]:
        layers.trainable = True

    x = resnet_model.output
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    
    x = tf.keras.layers.Dropout(0.2)(x)
    x = tf.keras.layers.Dense(1024, activation='relu')(x)
    x = tf.keras.layers.Dropout(0.2)(x)
    x = tf.keras.layers.Dense(256, activation='relu')(x)
    x = tf.keras.layers.Dropout(0.2)(x)
    # output layer
    predictions = tf.keras.layers.Dense(4, activation='softmax')(x)

    res_model = tf.keras.Model(inputs=resnet_model.input, outputs=predictions)

    # Compiling the model
    res_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return res_model

res_model = create_model()

res_model.summary()

metrics = [keras.metrics.CategoricalAccuracy(name='accuracy'),
           keras.metrics.Precision(name='precision'),
           keras.metrics.Recall(name='recall'),
           keras.metrics.AUC(name='auc')]

epo = 5
b_size = 8